{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbb4b0b",
   "metadata": {
    "id": "9fbb4b0b"
   },
   "source": [
    "# CP 218 Workshop 5\n",
    "## Linear Regression with Bayesian View\n",
    "***\n",
    "In this workshop, first we'll look at linear regression through both Frquentist (Likelihood estimate) and Bayesian prespective (Bayesian Linear Regression). Briefly, this involves learning a linear regression model from a training set of $(\\mathbf{x}, y)$ pairs, where $\\mathbf{x}$ is a feature vector and $y$ is a real-valued response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366b8ae1",
   "metadata": {
    "id": "366b8ae1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5dc9c0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5dc9c0b",
    "outputId": "2a49b0fd-4df1-42f6-d438-08308a720472"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45298711, -0.00912573,  0.88266582,  1.25521852,  0.20548559,\n",
       "        -0.35642973, -0.27199956, -0.30055816,  0.39853407,  0.62269211]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.random.randn(1,10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221021ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "221021ff",
    "outputId": "9d91ecdc-347e-4246-e284-6497a7affcb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 10), dtype=float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-1]\n",
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532884d3",
   "metadata": {
    "id": "532884d3"
   },
   "outputs": [],
   "source": [
    "np.arange?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353e743",
   "metadata": {
    "id": "3353e743"
   },
   "source": [
    "### 1. Review\n",
    "In this week's lecture, we saw that a linear model can be expressed as:\n",
    "$$y = w_0 + \\sum_{j = 1}^{m} w_j x_j = \\mathbf{w} \\cdot \\mathbf{x} $$\n",
    "where\n",
    "\n",
    "* $y$ is the *target (or output) variable*;\n",
    "* $\\mathbf{x} = [x_1, \\ldots, x_m]$ is a vector of *features* or *predictors* (we define $x_0 = 1$); and\n",
    "* $\\mathbf{w} = [w_0, \\ldots, w_m]$ are the *weights*.\n",
    "\n",
    "To fit the model, we will *minimise* the residual sum of squares (RSS) (simple case) which is also an MLE estimate for linear regression:\n",
    "\n",
    "$$RSS(\\mathbf{w}) = \\sum_{i=1}^{n}(y_i - \\mathbf{w} \\cdot \\mathbf{x}_i)^2$$\n",
    "\n",
    "**Note:** For simplicity, we'll consider the case $m = 1$ (i.e. only one feature excluding the intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8507b",
   "metadata": {
    "id": "ecc8507b"
   },
   "source": [
    "***Problem Statement***\n",
    "\n",
    "Suppose you work as a consultant to a start-up company that was looking to develop a model to estimate the manufacturing cost (cost of goods sold) in future. The startup gathered data and has asked you to develop a model to predict the year vs. the manufacturing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a33715a",
   "metadata": {
    "id": "2a33715a"
   },
   "outputs": [],
   "source": [
    "csv = \"\"\"1896,4.47083333333333\n",
    "1900,4.46472925981123\n",
    "1904,5.22208333333333\n",
    "1908,4.1546786744085\n",
    "1912,3.90331674958541\n",
    "1920,3.5695126705653\n",
    "1924,3.8245447722874\n",
    "1928,3.62483706600308\n",
    "1932,3.59284275388079\n",
    "1936,3.53880791562981\n",
    "1948,3.6701030927835\n",
    "1952,3.39029110874116\n",
    "1956,3.43642611683849\n",
    "1960,3.2058300746534\n",
    "1964,3.13275664573212\n",
    "1968,3.32819844373346\n",
    "1972,3.13583757949204\n",
    "1976,3.07895880238575\n",
    "1980,3.10581822490816\n",
    "1984,3.06552909112454\n",
    "1988,3.09357348817\n",
    "1992,3.16111703598373\n",
    "1996,3.14255243512264\n",
    "2000,3.08527866650867\n",
    "2004,3.1026582928467\n",
    "2008,2.99877552632618\n",
    "2012,3.03392977050993\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cacd97",
   "metadata": {
    "id": "15cacd97"
   },
   "outputs": [],
   "source": [
    "# Read into a numpy array (as floats)\n",
    "manufacturing_data = np.genfromtxt(io.BytesIO(csv.encode()), delimiter=\",\")\n",
    "x = manufacturing_data[:, 0:1]\n",
    "y = manufacturing_data[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb64f0",
   "metadata": {
    "id": "64bb64f0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x, y, alpha=0.2, color='red')\n",
    "plt.ylabel(\"y (Cost)\")\n",
    "plt.xlabel(\"x (Year)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeeaef0",
   "metadata": {
    "id": "faeeaef0"
   },
   "source": [
    "### Analytical  Solution (Normal Equation)\n",
    "\n",
    "In lecture, we saw that it's possible to solve for the optimal weights $\\mathbf{w}^\\star$ analytically. The solution is (MLE estimate)\n",
    "$$\\mathbf{w}^* = \\left[\\mathbf{X}^\\top \\mathbf{X}\\right]^{-1} \\mathbf{X}^\\top \\mathbf{y}$$\n",
    "where\n",
    "$$\\mathbf{X} = \\begin{pmatrix}\n",
    "        1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n\n",
    "    \\end{pmatrix}\n",
    "  \\quad \\text{and} \\quad\n",
    "  \\mathbf{y} = \\begin{pmatrix}\n",
    "          y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "      \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We construct $\\mathbf{X}$ in the code block below, remembering to include the $x_0 = 1$ column for the bias (intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c9752",
   "metadata": {
    "id": "350c9752"
   },
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones_like(x), x))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488333f5",
   "metadata": {
    "id": "488333f5"
   },
   "source": [
    "To get the solution using Normal eequation, we solve the following system of linear equations:\n",
    "$$\\mathbf{X}^\\top\\mathbf{X} \\mathbf{w}^\\star = \\mathbf{X}^\\top\\mathbf{y}$$\n",
    "\n",
    "This can be done in numpy using the command `np.linalg.solve`. Dot product can be done using `np.dot`. (Try `np.linalg.solve?` or `np.dot?` in a cell to see what inputs they take\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68df660",
   "metadata": {
    "id": "d68df660"
   },
   "outputs": [],
   "source": [
    "w = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d7429",
   "metadata": {
    "id": "762d7429"
   },
   "source": [
    "Let's examine the quality of fit for these values for the weights $w_0$ and $w_1$. We create a vector of \"test\" values `x_test` and a function to compute the predictions according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93097e01",
   "metadata": {
    "id": "93097e01"
   },
   "outputs": [],
   "source": [
    "x_test = np.arange(1890, 2032)[:, None]\n",
    "\n",
    "def predict(x_test, w0, w1):\n",
    "    return w0 + w1 * x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b28f90",
   "metadata": {
    "id": "15b28f90"
   },
   "outputs": [],
   "source": [
    "w0, w1 = w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabf088",
   "metadata": {
    "id": "ceabf088"
   },
   "source": [
    "Now plot the test predictions with a blue line on the same plot as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c4f38",
   "metadata": {
    "id": "cf1c4f38"
   },
   "outputs": [],
   "source": [
    "def plot_fit(x_test, y_test, x, y):\n",
    "    plt.plot(x_test, y_test, 'b-')\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylabel(\"y (Cost)\")\n",
    "    plt.xlabel(\"x (Year)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_fit(x_test, predict(x_test, w0, w1), x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7175f62e",
   "metadata": {
    "id": "7175f62e"
   },
   "source": [
    "We'll compute the residual sum of squares $RSS(w_0,w_1)$ on the training set to measure the goodness of fit.\n",
    "\n",
    "Expanding out the RSS for this simple case (where $\\mathbf{w}=[w_0, w_1]$) we have:\n",
    "$$RSS(w_0, w_1) = \\sum_{i=1}^{n}(y_i - w_0 - w_1 x_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6076a",
   "metadata": {
    "id": "5fe6076a"
   },
   "outputs": [],
   "source": [
    "def compute_RSS(x, y, w0, w1):\n",
    "    return ((y - w0 - w1*x)**2).sum()\n",
    "\n",
    "print(compute_RSS(x, y, w0, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a567131",
   "metadata": {
    "id": "3a567131"
   },
   "source": [
    "The error we computed above is the *training* error. It doesn't assess the model's generalization ability, it only assesses how well it's performing on the given training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5afa6b",
   "metadata": {
    "id": "7a5afa6b"
   },
   "source": [
    "### Model Complexity and Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4edb8",
   "metadata": {
    "id": "a8f4edb8"
   },
   "source": [
    "Now we will review overfitting, model selection and regularisation. Note that the lessons here apply equally to classification, however it's more convenient to visualise regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3526335",
   "metadata": {
    "id": "d3526335"
   },
   "source": [
    "Now we will consider a more complex polynomial function. Where before we had instances of the form,\n",
    "$$\\phi(\\mathbf{x}) = [ 1~ x ]$$\n",
    "now we will be using e.g.,\n",
    "$$\\phi(\\mathbf{x}) = [ 1 ~x~ x^2~ x^3~ x^4]$$\n",
    "for a quartic model. We will consider a range of polynomial models of different orders.\n",
    "\n",
    "To implement this we will use *basis functions* which provide a neat way of representing our data instances such that we can still use all the linear models to achieve learn a non-linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdac33",
   "metadata": {
    "id": "dbbdac33"
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02d629",
   "metadata": {
    "id": "bd02d629"
   },
   "outputs": [],
   "source": [
    "num_data = x.shape[0]\n",
    "num_pred_data = 100 # how many points to use for plotting predictions\n",
    "x_pred = np.linspace(1890, 2016, num_pred_data)[:, None] # input locations for predictions\n",
    "order = 4 # The polynomial order to use.\n",
    "print ('Num of training samples: ',num_data)\n",
    "print('Num of testing samples: ',num_pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad533e6a",
   "metadata": {
    "id": "ad533e6a"
   },
   "source": [
    "Now let's build the *basis* matrices $\\Phi$ to represent the training data, where each column is raising the input year $X$ to various powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a320d7aa",
   "metadata": {
    "id": "a320d7aa"
   },
   "outputs": [],
   "source": [
    "Phi = np.zeros((num_data, order+1))\n",
    "Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "for i in range(0, order+1):\n",
    "    Phi[:, i:i+1] = x**i\n",
    "    Phi_pred[:, i:i+1] = x_pred**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07747e12",
   "metadata": {
    "id": "07747e12"
   },
   "outputs": [],
   "source": [
    "Phi_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a4ce0",
   "metadata": {
    "id": "dc2a4ce0"
   },
   "source": [
    "### Fitting the model\n",
    "\n",
    "Now we can solve for the regression weights and make predictions both for the training data points, and the test data points. That involves solving the linear system given by\n",
    "\n",
    "$$\\Phi' \\Phi \\mathbf{w} = \\Phi' \\mathbf{y}$$\n",
    "\n",
    "with respect to $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fa9ef",
   "metadata": {
    "id": "a43fa9ef"
   },
   "outputs": [],
   "source": [
    "# solve the linear system\n",
    "w = np.linalg.solve(np.dot(Phi.T, Phi), np.dot(Phi.T, y))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac1942fa",
   "metadata": {
    "id": "ac1942fa"
   },
   "outputs": [],
   "source": [
    "#use resulting vector to make predictions at the training points and test points\n",
    "f = np.dot(Phi, w)\n",
    "f_pred = np.dot(Phi_pred, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08720a0",
   "metadata": {
    "id": "a08720a0"
   },
   "outputs": [],
   "source": [
    "# compute the residual sum of squares (error)\n",
    "RSS = ((y-f)**2).sum()\n",
    "RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ca4ac",
   "metadata": {
    "id": "f59ca4ac"
   },
   "outputs": [],
   "source": [
    "#Now we have the fit and the error, so let's plot the fit and the error.\n",
    "\n",
    "print(\"The error is: %2.4f\"%RSS)\n",
    "plt.plot(x_pred, f_pred)\n",
    "plt.plot(x, y, 'rx')\n",
    "ax = plt.gca()\n",
    "ax.set_title('Predictions for Order 4')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496e281",
   "metadata": {
    "id": "6496e281"
   },
   "source": [
    "Now use the loop structure below to compute the error for different model orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff4e6d",
   "metadata": {
    "id": "87ff4e6d"
   },
   "outputs": [],
   "source": [
    "# import the time model to allow python to pause.\n",
    "# import the IPython display module to clear the output.\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "error_list = []\n",
    "max_order = 6\n",
    "fig1=plt.figure(figsize=(15,2*max_order))\n",
    "index=1\n",
    "\n",
    "for order in range(0, max_order+1):\n",
    "    # 1. build the basis set\n",
    "    Phi = np.zeros((num_data, order+1))\n",
    "    Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "    for i in range(0, order+1):\n",
    "        Phi[:, i:i+1] = x**i\n",
    "        Phi_pred[:, i:i+1] = x_pred**i\n",
    "    # 2. solve the linear system\n",
    "    w = np.linalg.solve(np.dot(Phi.T, Phi), np.dot(Phi.T, y))\n",
    "\n",
    "    # 3. make predictions at training and test points\n",
    "    f = np.dot(Phi, w)\n",
    "    f_pred = np.dot(Phi_pred, w)\n",
    "\n",
    "    # 4. compute the training error and append it to a list.\n",
    "    RSS = ((y-f)**2).sum()\n",
    "    error_list.append(RSS)\n",
    "\n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(max_order+1,2,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim((2.5, 5.5))\n",
    "    if (order <7):\n",
    "        plt.title('Predictions for Order ' + str(order) + ' model.')\n",
    "\n",
    "\n",
    "    fig1.add_subplot(max_order+1,2,index+1)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.6)\n",
    "    plt.plot(np.arange(0, order+1), np.asarray(error_list))\n",
    "    plt.xlim((0, order+1))\n",
    "    plt.ylim((0, np.max(error_list)))\n",
    "    if (order ==0):\n",
    "        plt.title('Training Error')\n",
    "    index= index+2\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Training error list: ',error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b621e2",
   "metadata": {
    "id": "a3b621e2"
   },
   "source": [
    "**Home Task:** Looks like a great fit. Does that mean we can stop here, our job is done? You might want to try an order 20 or higher model, also to see if the fits continue to improve with higher order models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb506cd",
   "metadata": {
    "id": "cfb506cd"
   },
   "source": [
    "**Discussion:** What do you think might happen if we try to fit an order 100 model to this data? Is this even a reasonable thing to try?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174c2b",
   "metadata": {
    "id": "12174c2b"
   },
   "source": [
    "### Model Generalization using Hold-out Validation\n",
    "The error we computed above is the training error. It doesn't assess the model's generalization ability, it only assesses how well it's performing on the given training data.\n",
    "\n",
    "\n",
    "In hold out validation, we keep back some of the training data for assessing generalization performance. In the case of time series prediction, it often makes sense to hold out the last few data points, in particular, when we are interested in *extrapolation*, i.e. predicting into the future given the past. To perform hold out validation, we first remove the hold out set. If we were interested in interpolation, we would hold out some random points. Here, because we are interested in extrapolation, we will hold out all points since 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529a9f6",
   "metadata": {
    "id": "1529a9f6"
   },
   "outputs": [],
   "source": [
    "# Create a training set\n",
    "x_train = x\n",
    "y_train = y\n",
    "indices_hold_out = np.nonzero(x>1980)\n",
    "\n",
    "\n",
    "x_train = np.delete(x, indices_hold_out)[:,None]\n",
    "y_train = np.delete(y, indices_hold_out)[:,None]\n",
    "\n",
    "# Create a hold out set\n",
    "x_hold_out = x[indices_hold_out][:,None]\n",
    "y_hold_out = y[indices_hold_out][:,None]\n",
    "\n",
    "\n",
    "print ('Whole dataset size', x.shape)\n",
    "print('Train split size: ', x_train.shape)\n",
    "print('Test split size: ', x_hold_out.shape)\n",
    "\n",
    "# Now use the training set and hold out set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8426f87",
   "metadata": {
    "id": "a8426f87"
   },
   "source": [
    "Now you have the training and hold out data, you should be able to use the code above to evaluate the model on the hold out data. Do this in the code block below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb43b4",
   "metadata": {
    "id": "28fb43b4"
   },
   "outputs": [],
   "source": [
    "error_list = []\n",
    "max_order = 6\n",
    "fig1=plt.figure(figsize=(12,max_order*2))\n",
    "index = 1\n",
    "for order in range(0, max_order+1):\n",
    "    # 1. build the basis set using x_train, x_hold_out, and prediction set\n",
    "    Phi = np.zeros((x_train.shape[0], order+1))\n",
    "    Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "    Phi_hold_out = np.zeros((x_hold_out.shape[0], order+1))\n",
    "    for i in range(0, order+1):\n",
    "        Phi[:, i:i+1] = x_train**i\n",
    "        Phi_hold_out[:, i:i+1] = x_hold_out**i\n",
    "        Phi_pred[:, i:i+1] = x_pred**i\n",
    "\n",
    "    # 2. solve the linear system\n",
    "    w = np.linalg.solve(np.dot(Phi.T, Phi), np.dot(Phi.T, y_train))\n",
    "\n",
    "    # 3. make predictions at training, hold_out, and prediction points\n",
    "    f = np.dot(Phi, w)\n",
    "    f_hold_out = np.dot(Phi_hold_out, w)\n",
    "    f_pred = np.dot(Phi_pred, w)\n",
    "\n",
    "    # 4. compute the hold out error and append it to a list.\n",
    "    error = ((y_hold_out-f_hold_out)**2).sum()\n",
    "    error_list.append(error)\n",
    "\n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(max_order+1,2,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim((2.5, 5.5))\n",
    "    if (order <7):\n",
    "        plt.title('Predictions for Order ' + str(order) + ' model.')\n",
    "\n",
    "    fig1.add_subplot(max_order+1,2,index+1)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.6)\n",
    "    fig1.add_subplot(max_order+1,2,index+1)\n",
    "    plt.plot(np.arange(0, order+1), np.asarray(error_list))\n",
    "    plt.xlim((0, order+1))\n",
    "    plt.ylim((0, np.max(error_list)))\n",
    "    if (order ==0):\n",
    "        plt.title('Hold out Error')\n",
    "    index= index+2\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Holdout error list: ', error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bbb60",
   "metadata": {
    "id": "0d3bbb60"
   },
   "source": [
    "**Discussion:** What is going on here? Does this match your earlier findings, or your intuition about which model order was most appropriate? Why isn't held-out error behaving the same as training error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521fa8d",
   "metadata": {
    "id": "9521fa8d"
   },
   "source": [
    "### Ridge regression (Regularization)- Also the MAP estimate\n",
    "\n",
    "A nice way to limit model complexity is *regularisation* where model parameters are penalised from moving to high magnitude values (which means the model is getting overly confident)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e35c8",
   "metadata": {
    "id": "2f5e35c8"
   },
   "source": [
    "For this exercise, we'll use a 6th order model, which you might consider much too powerful for this simple problem. As a first step, we'll preprocess the features to ensure they are all operating in a similar range. E.g., $2000^6 >> 2000^1$, which means the weights for the 6th order features will take on radically different values to the 1st order features. (Recall that when we regularize, we encourage weights to be small. A weight associated with the higher orders of feature (e.g. year in this case) can be smaller than a weight associated with the other (low orders) feature and express the same thing. So, we're not letting the data decide which features to weight more heavily, we've accidentally biased it towards favoring the first to the second.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To correct for this, and allow regularisation with a single constant, we'll normalize (z-score) the columns of training Phi to have zero mean and unit standard deviation. This same transformation is also applied to the testing basis matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5a061",
   "metadata": {
    "id": "21f5a061"
   },
   "outputs": [],
   "source": [
    "order = 6\n",
    "Phi = np.zeros((x_train.shape[0], order+1))\n",
    "Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "Phi_hold_out = np.zeros((x_hold_out.shape[0], order+1))\n",
    "for i in range(0, order+1):\n",
    "    Phi[:, i:i+1] = x_train**i\n",
    "    if i > 0:\n",
    "        mean = Phi[:, i:i+1].mean()\n",
    "        std = Phi[:, i:i+1].std()\n",
    "        print(i,mean,std)\n",
    "    else: # as the first column is constant, need to avoid divide by zero\n",
    "        mean = 0\n",
    "        std = 1\n",
    "\n",
    "    Phi[:, i:i+1] = (Phi[:, i:i+1] - mean) / std\n",
    "    Phi_hold_out[:, i:i+1] = (x_hold_out**i - mean) / std\n",
    "    Phi_pred[:, i:i+1] = (x_pred**i - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7965fd3",
   "metadata": {
    "id": "b7965fd3"
   },
   "outputs": [],
   "source": [
    "#Next we'll perform training, trying out different values of the regularisation coefficient, lambda.\n",
    "\n",
    "error_list = []\n",
    "train_error_list = []\n",
    "lambdas = [1e-10, 1e-6, 1e-4, 1e-2, 1, 100]\n",
    "order = 6\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "fig1=plt.figure(figsize=(16,order*4))\n",
    "index =1\n",
    "for l, lamba in enumerate(lambdas):\n",
    "    # 1. build the basis set using x_train, x_hold_out\n",
    "    # done above\n",
    "\n",
    "    # 2. solve the linear system\n",
    "    w = np.linalg.solve(np.dot(Phi.T, Phi) + lamba * np.eye(order+1), np.dot(Phi.T, y_train))\n",
    "\n",
    "    # 3. make predictions at training and test points\n",
    "    f = np.dot(Phi, w)\n",
    "    f_hold_out = np.dot(Phi_hold_out, w)\n",
    "    f_pred = np.dot(Phi_pred, w)\n",
    "\n",
    "    # 4. compute the hold and training error and append it to a list.\n",
    "    error = ((y_hold_out-f_hold_out)**2).sum()\n",
    "    error_list.append(error)\n",
    "    train_error = ((y_train-f)**2).sum()\n",
    "    train_error_list.append(train_error)\n",
    "\n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(len(lambdas)+1,3,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim(2.5, 5.5)\n",
    "    if (l==0):\n",
    "        plt.title('Pred. for Lambda ' + str(lamba))\n",
    "    else:\n",
    "        plt.title(str(lamba))\n",
    "\n",
    "    fig1.add_subplot(len(lambdas)+1,3,index+1)\n",
    "    plt.plot(lambdas[:l+1], np.asarray(error_list))\n",
    "    plt.xlim((min(lambdas), max(lambdas)))\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 12)\n",
    "    if (l==0):\n",
    "        plt.title('Held-out Error (validation/testing)')\n",
    "\n",
    "\n",
    "    fig1.add_subplot(len(lambdas)+1,3,index+2)\n",
    "    plt.plot(lambdas[:l+1], np.asarray(train_error_list))\n",
    "    plt.xlim(min(lambdas), max(lambdas))\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 12)\n",
    "    if (l == 0):\n",
    "        plt.title('Training Error')\n",
    "    index= index+3\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Holdout error list: ',error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f7364",
   "metadata": {
    "id": "8d1f7364"
   },
   "source": [
    "**Discussion:** What setting gives the best heldout performance? How does this relate to the training error, and can you describe whether you see evidence of overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40056ffa",
   "metadata": {
    "id": "40056ffa"
   },
   "source": [
    "Now that you have a good understanding of what's going on under the hood in Linear Regression, you can use the functionality in `sklearn` to solve linear regression problems you encounter in the future. Using the `LinearRegression` module, fitting a linear regression model becomes a one-liner as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833aab1f",
   "metadata": {
    "id": "833aab1f"
   },
   "outputs": [],
   "source": [
    "# Try at home\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(x, y)\n",
    "lr.intercept_\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b20225",
   "metadata": {
    "id": "37b20225"
   },
   "source": [
    "## Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a5ca2",
   "metadata": {
    "id": "d10a5ca2"
   },
   "source": [
    "We'll now look at *Bayesian* inference. We will be using sklearn library for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5b662",
   "metadata": {
    "id": "60c5b662"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3edf73d",
   "metadata": {
    "id": "c3edf73d"
   },
   "source": [
    "### Small Synthetic Dataset\n",
    "We'll keep the data set small, since Bayesian approaches are particularly useful when limited data is available.\n",
    "\n",
    "\n",
    "So, let's generate a small synthetic data set in 1D according to the following model:\n",
    "$$\n",
    "\\newcommand\\ys{\\mathbf{y}}\n",
    "\\newcommand\\xs{\\mathbf{x}}\n",
    "\\newcommand\\Xs{\\mathbf{X}}\n",
    "\\newcommand\\ws{\\mathbf{w}}\n",
    "\\newcommand\\Vs{\\mathbf{V}}\n",
    "\\newcommand\\Is{\\mathbf{I}}\n",
    "\\begin{align*}\n",
    "x &\\sim \\mathrm{Uniform}[0,1] \\\\\n",
    "y|x, \\sigma^2 &\\sim \\mathrm{Normal}\\!\\left[5\\left(x - \\frac{1}{2}\\right)^2, \\sigma^2 \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "By focussing on the 1D case, it'll be straightforward to visualise the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb10d28",
   "metadata": {
    "id": "2cb10d28"
   },
   "outputs": [],
   "source": [
    "n = 8 # number of instances\n",
    "\n",
    "# parameters\n",
    "sigma = 0.1 # keep this small: don't want too much noise\n",
    "\n",
    "# generate data matrix with rows as instances\n",
    "X = np.random.uniform(size=(n,1))\n",
    "\n",
    "# generate the target response values using the quadratic function and additive noise\n",
    "Y = np.random.normal(loc=5*(X - 0.5)**2, scale=sigma, size=(n,1)).ravel()\n",
    "\n",
    "# plot the training data\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "\n",
    "# and plot the true function (without noise)\n",
    "X_test = np.linspace(-0.2, 1.2, 100)\n",
    "X_test = X_test[:,np.newaxis]\n",
    "Y_test_true = 5*(X_test - 0.5)**2\n",
    "plt.plot(X_test, Y_test_true, 'k', label='True')\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2680",
   "metadata": {
    "id": "196f2680"
   },
   "source": [
    "#### Polynomial basis functions\n",
    "Since the relationship between $y$ and $x$ is non-linear, we'll apply polynomial basis expansion to degree $d$.\n",
    "Specifically, we replace the original data matrix $\\mathbf{X}$ by the transformed matrix $\\mathbf{\\Phi}$, as we have seen before in this workshop. Note that we have to include a column of ones to account for the bias term.\n",
    "\n",
    "The function below is a wrapper around `sklearn.preprocessing.PolynomialFeatures`, which implements the above transformation on a train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931806d7",
   "metadata": {
    "id": "931806d7"
   },
   "outputs": [],
   "source": [
    "def polynomial_features(X_train, X_test, degree, include_bias=True):\n",
    "    \"\"\"\n",
    "    Augments data matrices X_train and X_test with polynomial features\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=include_bias)\n",
    "\n",
    "    Phi_train = poly.fit_transform(X_train)\n",
    "    Phi_test = poly.fit_transform(X_test)\n",
    "\n",
    "    return Phi_train, Phi_test\n",
    "\n",
    "Phi, Phi_test = polynomial_features(X, X_test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6769b",
   "metadata": {
    "id": "76a6769b"
   },
   "source": [
    "### Bayesian Regression with Known Variance\n",
    "Let's begin with a quick recap on Bayesian Linear Regression. The model assumes the data is generated according to a Normal distribution, where the mean is a linear function of the input vector and the variance $\\sigma^2$ is **assumed known**.\n",
    "The prior over the weight vector $\\ws$ is also Normal—by setting the mean to zero and choosing a small $\\gamma^2$, weights with large magnitude are penalised.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ws | \\gamma &\\sim \\mathrm{Normal}\\!\\left[\\mathbf{0}, \\gamma^2 \\mathbf{I}_m\\right] & \\mbox{Prior} \\\\\n",
    "y | \\mathbf{x}, \\mathbf{w}, \\sigma &\\sim \\mathrm{Normal}\\!\\left[\\xs^\\intercal \\ws, \\sigma^2\\right] & \\mbox{Likelihood}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5330a9",
   "metadata": {
    "id": "be5330a9"
   },
   "source": [
    "Given this formulation, the next step is to solve for the posterior over $\\ws$\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\ws | \\Xs, \\ys, \\sigma, \\gamma) = \\frac{p(\\ys | \\Xs, \\ws, \\sigma) p(\\ws | \\gamma)}{p(\\ys | \\Xs, \\sigma)}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\Xs \\in \\mathbb{R}^{n \\times m}$ is the feature matrix and $\\ys \\in \\mathbb{R}^{n}$ is the vector of target values for each instance.\n",
    "\n",
    "In lectures, we derived the following solution:\n",
    "$$\n",
    "\\ws | \\Xs, \\ys, \\sigma, \\gamma \\sim  \\textrm{Normal}(\\ws_N, \\mathbf{V}_N)\n",
    "$$\n",
    "where $\\Vs_N = \\sigma^2 \\left( \\Xs^\\intercal \\Xs + \\frac{\\sigma^2}{\\gamma^2} \\Is_m \\right)^{-1}$ and $\\ws_N = \\frac{1}{\\sigma^2} \\Vs_N \\Xs^\\intercal \\ys$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97320711",
   "metadata": {
    "id": "97320711"
   },
   "source": [
    "#### Computing the posterior parameters\n",
    "Complete the function below to compute the posterior mean $\\mathbf{w}_N$ and covariance matrix $\\mathbf{V}_N$ for the weights based on the expression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87339af",
   "metadata": {
    "id": "f87339af"
   },
   "outputs": [],
   "source": [
    "def compute_posterior_params(X, Y, sigma, gamma):\n",
    "    \"\"\"\n",
    "    Compute the parameters (mean and covariance) for the posterior over the weights\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    sigma : float\n",
    "        positive scale parameter for y\n",
    "    gamma : float\n",
    "        positive scale parameter for w_i\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    The following items in a tuple:\n",
    "    w_N : numpy array, shape: (n_features,)\n",
    "        mean parameter\n",
    "    V_N : numpy array, shape: (n_features, n_features)\n",
    "        covariance parameter\n",
    "    \"\"\"\n",
    "    V_N = sigma**2 * np.linalg.inv(X.T @ X + (sigma/gamma)**2 * np.identity(X.shape[1])) # fill in\n",
    "    w_N = np.ravel(1/sigma**2 * V_N @ X.T @ Y) # fill in\n",
    "\n",
    "    return w_N, V_N\n",
    "\n",
    "gamma = 10 # larger implies more permissive, i.e. a more diffuse prior\n",
    "w_N, V_N = compute_posterior_params(Phi, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fbfb1",
   "metadata": {
    "id": "538fbfb1"
   },
   "source": [
    "Let's plot the prior and posterior over $\\mathbf{w}$ to see how they differ.\n",
    "Since $\\mathbf{w}$ is $d+1$-dimensional, we can only visualise the posterior over a couple of the weights.\n",
    "Here we look at $p(w_1, w_2|\\mathbf{X}, \\mathbf{y}, \\sigma, \\gamma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15315f9",
   "metadata": {
    "id": "d15315f9"
   },
   "outputs": [],
   "source": [
    "# set up a 2d plot mesh\n",
    "w1, w2 = np.mgrid[-10:10:.05, -10:10:.05]\n",
    "grid = np.c_[w1.ravel(), w2.ravel()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "# plot a bivariate normal for the prior\n",
    "ax = fig.add_subplot(121)\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=np.zeros(2), cov=gamma**2 * np.identity(2))\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(0, 0, 'rx') # add prior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Prior $p(w_1, w_2|\\gamma)$')\n",
    "\n",
    "# plot a bivariate normal for the posterior\n",
    "ax = fig.add_subplot(122)\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=w_N[1:3], cov=V_N[1:3,1:3])\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(w_N[1], w_N[2], 'rx') # add posterior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Posterior $p(w_1, w_2|X,y,\\gamma,\\sigma)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5fda6",
   "metadata": {
    "id": "06d5fda6"
   },
   "source": [
    "**Discussion question**: Can you explain why the prior and the posterior are so different? How is this related to the dataset?  *You might want to change the parameter indices from 0,1 to other pairs to get a better idea of the full posterior.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a61c55",
   "metadata": {
    "id": "65a61c55"
   },
   "source": [
    "#### Bayesian Prediction (Inference)\n",
    "One way of doing inference for $y|\\mathbf{x}$ is to draw a sample of weight vectors from the posterior (sampling from a Gaussian).\n",
    "\n",
    "Complete the function below to compute the predictive mean $E[y|\\mathbf{x}] = \\mathbf{w} \\cdot \\mathbf{x}$.\n",
    "Then run the code block below to plot 50 samples from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7993768",
   "metadata": {
    "id": "c7993768"
   },
   "outputs": [],
   "source": [
    "def target_mean(X, w):\n",
    "    \"\"\"\n",
    "    Compute the predictive mean for the target variable, given X and w\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    Y_mean : numpy array, shape: (n_instances,)\n",
    "        predictive mean for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930f285",
   "metadata": {
    "id": "a930f285"
   },
   "outputs": [],
   "source": [
    "# generate some samples from the posterior\n",
    "for i in range(50):\n",
    "    # draw a weight vector\n",
    "    w_i = np.random.multivariate_normal(w_N, V_N, 1).ravel()\n",
    "    # plot the predictions for this weight vector\n",
    "    p = plt.plot(X_test.ravel(), target_mean(Phi_test, w_i), ':', lw=1)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.plot(X_test, target_mean(Phi_test, w_N), 'g:', label='Mean')\n",
    "plt.plot(X_test.ravel(), Y_test_true, 'k', label='True')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfdd13",
   "metadata": {
    "id": "0ecfdd13"
   },
   "source": [
    "***Discussion***: What do you observe from this plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b4c32",
   "metadata": {
    "id": "939b4c32"
   },
   "source": [
    "***Answer*** It's interesting to see what happens near the training data points, and away from them, in particular the edges of the plot.\n",
    "We'll come back to this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406759a",
   "metadata": {
    "id": "8406759a"
   },
   "source": [
    "There's a more elegant solution, as the predictive distribution can be found in closed form. Namely\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_{*} | \\xs_{*}, \\ws_N, \\Vs_N, \\sigma &= \\mathrm{Normal}\\!\\left[\\xs_{*}'\\ws_N, \\sigma^2_N(\\xs_{*})\\right] \\\\\n",
    "\\sigma^2_N(\\xs_{*}) & = \\sigma^2 + \\xs_{*}' \\Vs_N \\xs_{*}\n",
    "\\end{align*}\n",
    "$$\n",
    "Note that the predictive mean is a simple application of the posterior mean to the data point, but the predictive variance is a bit more complicated.\n",
    "\n",
    "A function below is written to evaluate the predictive standard deviation, i.e. $\\sigma_N(\\mathbf{x}_{*})$.\n",
    "Run the following code block to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b079eb",
   "metadata": {
    "id": "a8b079eb"
   },
   "outputs": [],
   "source": [
    "def target_std(X, V_N, sigma):\n",
    "    \"\"\"\n",
    "    Compute the predictive standard deviation for the target variable, given X, V_N and sigma\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    V_N : numpy array, shape: (n_features, n_features)\n",
    "        covariance parameter\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    std : numpy array, shape: (n_instances,)\n",
    "        predictive standard deviation for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    return np.sqrt(sigma**2 + np.sum(X * (X @ V_N), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a6ee6",
   "metadata": {
    "id": "db3a6ee6"
   },
   "outputs": [],
   "source": [
    "# compute the standard deviation using the formula above\n",
    "Y_test_mean = target_mean(Phi_test, w_N)\n",
    "Y_test_std = target_std(Phi_test, V_N, sigma)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test.ravel(), Y_test_mean, 'g:', label='Mean')\n",
    "plt.plot(X_test.ravel(), Y_test_true, 'k', label='True')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a1fef",
   "metadata": {
    "id": "7a3a1fef"
   },
   "source": [
    "**Discussion**: How does the uncertainty plot compare to the samples above? How does the uncertainty change relative to the distance from training points? Can you explain why?\n",
    "\n",
    "**Practical**: How does the setting of `gamma` affect the fit? How about the number of instances in the training set? Try some other values and see what happens.\n",
    "\n",
    "**Discussion**: Is a 9th order polynomial a good choice for this problem? Based on the results above, would you recommend this model, or make a different choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e722fc",
   "metadata": {
    "id": "10e722fc"
   },
   "source": [
    "You can now try `Bayesian Ridge` from `sklearn.linear_model` for future problems to apply Bayesian Ridge\n",
    "\n",
    "`from sklearn.linear_model import BayesianRidge`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d3cbe",
   "metadata": {
    "id": "b43d3cbe"
   },
   "source": [
    "### References\n",
    "1. Pattern Recognition and Machine Learning, Christopher Bishop, New York, Springer,  2006. (Chapter 3)\n",
    "2. Machine learning: A Probabilistic Perspective, Kevin Murphy, MIT Press, 2012. (Chapters 17, 18)\n",
    "3. Statistical Machine Learning Course Workshop, 2015, University of Melbourne, Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7c5fc",
   "metadata": {
    "id": "fab7c5fc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
